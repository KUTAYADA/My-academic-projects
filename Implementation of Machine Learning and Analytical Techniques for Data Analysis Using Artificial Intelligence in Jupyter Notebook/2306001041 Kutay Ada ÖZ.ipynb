{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4825b313-a374-4017-869d-096a5a5ab731",
      "cell_type": "code",
      "source": "# kütüphaneler eklenmesi gereken \nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report,f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils import DataConversionWarning\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder,MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nimport seaborn as sns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d672fdac-b2ad-4095-8b86-8f55e7d4f47e",
      "cell_type": "code",
      "source": "#Önce excel dosyasını okutalım.\n# Veriyi içeren CSV dosyasını pandas kullanarak veri çerçevesine (DataFrame) aktarır\ndf = pd.read_csv(\"data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cb2f73a0-862f-433c-967e-0a815b213086",
      "cell_type": "code",
      "source": "# 1.1\n# Veri kümesinin ilk 30 satırını görüntüleyerek genel bir ön inceleme yapılmasını sağlar\ndf.head(30)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3d900256-e7f6-485e-8374-8f711e7c6298",
      "cell_type": "code",
      "source": "# 1.2\n# Veri kümesinde kaç satır ve kaç sütun olduğunu (boyutunu) öğrenmek için kullanılır\ndf.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "00e63b39-c8f7-40dd-abef-c1a54ad7b382",
      "cell_type": "code",
      "source": "# 1.3\n# Veri kümesindeki tüm sütun adlarını listelemek için kullanılır\ndf.columns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fd6776ad-d81f-4f2d-97b6-d9c95f979915",
      "cell_type": "code",
      "source": "#2\n# 'diagnosis' sütunundaki her bir sınıfın kaç kez tekrarlandığını (frekansını) gösterir\ndf['diagnosis'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "df22258f-de14-443c-945c-a636b4d61312",
      "cell_type": "code",
      "source": "#3\n# 'diagnosis' sütunundaki sınıfların dağılımını görselleştirmek için çubuk grafik (countplot) oluşturur\nsns.countplot(x=\"diagnosis\", data=df)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8c2d04f5-f4d9-4da0-bd0d-4b6026b9291d",
      "cell_type": "code",
      "source": "# 4.1\n# Her sütunda bulunan eksik (null) veri sayısını kontrol ederek eksiklik durumunu raporlar\ndf.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "26052993-70c0-469a-bb74-a7ce24c2e550",
      "cell_type": "code",
      "source": "# 4.2\n# 'diagnosis' sütunundaki eksik verileri, bu sütunun ortalama değeriyle doldurur\ndf['diagnosis'].fillna(df.diagnosis().mean(), inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e7355512-e607-4641-92fe-e61787ebd93c",
      "cell_type": "code",
      "source": "# 5.1\n# Veri çerçevesindeki tüm sütunlara ait temel istatistiksel özet bilgilerini (ortalama, std, min, max vb.) transpoze edilmiş şekilde gösterir\ndf.describe().T",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b973803f-ec64-46e2-a770-de031a515ad4",
      "cell_type": "code",
      "source": "# 5.2\n# 'radius_mean' sütunundaki verilerin aritmetik ortalamasını hesaplar\nb = df['radius_mean'].mean()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "480429d0-fa0c-46dc-aeed-2921c228cae5",
      "cell_type": "code",
      "source": "# 5.3\n# 'radius_mean' sütunundaki tüm değerlerin toplamını hesaplar\na = df['radius_mean'].sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0d995d18-def4-42e1-8c7f-4b2869cc3969",
      "cell_type": "code",
      "source": "# 5.4 \n# 'radius_mean' sütunundaki en büyük (maksimum) değeri belirler\nc = df['radius_mean'].max()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5b0225ae-1751-4625-8bbb-8e61742c0da8",
      "cell_type": "code",
      "source": "#İşlemlerin Toplu Hali\ndf.describe().T\nb=df['radius_mean'].mean()\na=df['radius_mean'].sum()\nc=df['radius_mean'].max()\n\n# Hesaplanan istatistiksel değerleri ekrana yazdırır\nprint (\"en büyük deger :\", c, \" \\ntoplamı :\", a, \"\\nortalaması :\",b)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "81eabe54-dd63-4425-85b8-dd02282d17d1",
      "cell_type": "code",
      "source": "# 'diagnosis' sütununun veri tipini öğrenmek için kullanılır\ndf['diagnosis'].dtype",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1d8748fe-5a3f-4087-b39b-2d07a282c375",
      "cell_type": "code",
      "source": "#6\n# Makine öğrenmesi modelleri için 'diagnosis' sütununu hedef değişken (y) olarak ayırır ve geri kalan tüm sütunları özellik (x) olarak belirler\nx = df.drop(\"diagnosis\", axis=1)\ny = df['diagnosis']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f897420e-2e2d-4c01-be3c-5c4f518a2e1e",
      "cell_type": "code",
      "source": "# 6.1\n# Özelliklerin ölçeklendirilmesi için StandardScaler nesnesi oluşturulur ve x verisi normalize edilerek standart skala dönüşümü uygulanır\nscaler = StandardScaler()\nx_sc = scaler.fit_transform(x)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d57b7a5c-8435-4f31-a74f-7b43f38386b8",
      "cell_type": "code",
      "source": "#6.2\n# Verinin daha okunabilir olması için sütun adlarıyla birlikte yeniden biçimlendirme\na=x_sc=pd.DataFrame(x_sc,columns=x.columns)\n\n# Ölçeklendirme işleminin çıktısını incelemek için\nprint(a.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "71caf9c4-b036-4113-b0f2-47f479bd81b0",
      "cell_type": "code",
      "source": "#7\n# Kategorik (string) verileri sayısal değerlere dönüştürmek için LabelEncoder kullanımı\nlabel=LabelEncoder()\ndf['diagnosis'] = label.fit_transform(df['diagnosis'])\ndf['Unnamed: 32'] = label.fit_transform(df['Unnamed: 32'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "26394080-3f06-420c-a203-8515f9dbe7c5",
      "cell_type": "code",
      "source": "print (df['diagnosis'])\nprint(df['Unnamed: 32'])",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a33b3965-9e39-4624-b1b6-5b041a25f1ff",
      "cell_type": "code",
      "source": "#8\n# Burada, bağımlı değişken olarak hangi değeri kullanmak istediğini seçmen isteniyor.\n# Yani, analizde hangi değişkenin hedef (bağımlı) olacağını belirtmelisin.\nx = df.drop(\"diagnosis\", axis=1)  # Bağımsız değişkenler (hedef dışındaki tüm özellikler)\ny = df['diagnosis']               # Bağımlı değişken (tahmin edilmek istenen etiket)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f05c0227-8892-47ca-a704-790bdb3beab3",
      "cell_type": "code",
      "source": "#9 bölüm cevapları :\n# Veriyi eğitim (train) ve test kümelerine ayırmak için kullanılır.\n# x: bağımsız değişkenler, y: bağımlı değişken (hedef).\n# test_size=0.3 → verinin %30'u test, %70'i eğitim için ayrılır.\n# random_state=0 → işlemin her seferinde aynı şekilde tekrarlanmasını sağlar.\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "337a7953-6b22-48f0-998c-e658cec661e9",
      "cell_type": "code",
      "source": "#10 bölüm cevaspları :\n# öGrenme algoritmaları : 4 ayrılıyor : sprot meacl learng - random frost - \n\"\"\"\n1. Destek Vektör Makineleri (Support Vector Machine – SVM)\nSVM, sınıflandırma problemlerinde verileri en iyi ayıran hiper düzlemi bulmayı hedefler. \nTemel amacı, iki sınıf arasındaki marjini maksimize ederek genelleme performansını artırmaktır.\n\nKernel (çekirdek) fonksiyonları sayesinde doğrusal olarak ayrılmayan veriler de dönüştürülerek sınıflandırılabilir:\n\nLinear: Veriler doğrusal olarak ayrılabiliyorsa tercih edilir.\n\nPolynomial (Poly): Verileri polinom derecesine göre dönüştürerek daha karmaşık ayrım yüzeyleri oluşturur.\n\nRBF (Radial Basis Function): Özellikle doğrusal olmayan sınıflandırma problemlerinde yaygın olarak kullanılır.\n\n2. Random Forest (Rassal Orman)\nRandom Forest, birden çok karar ağacından oluşan topluluk (ensemble) yöntemidir.\nHer ağaç bağımsız olarak eğitilir ve nihai karar, bu ağaçların çoğunluk oyuna göre verilir.\nAşırı öğrenme (overfitting) riskini azaltır, yüksek doğruluk sağlar ve modelin genelleme yeteneğini artırır.\n\n3. Karar Ağaçları (Decision Tree)\nKarar ağaçları, veriyi özelliklerine göre dallara ayırarak sınıflandırma yapar.\nHer düğümde en uygun özelliğe göre bir bölünme gerçekleşir. \nYorumlanması ve görselleştirilmesi oldukça kolaydır. \nAncak tek başına kullanıldığında aşırı öğrenmeye eğilimlidir.\n\n4. Lojistik Regresyon (Logistic Regression)\nLojistik regresyon, sınıflandırma problemleri için kullanılan istatistiksel bir modeldir. \nModelin çıktısı, 0 ile 1 arasında değişen olasılık değeridir.\nÖzellikle ikili sınıflandırma problemlerinde etkilidir ve karar eşiklerine göre sınıflandırma yapılabilir.\n\n5. Yapay Sinir Ağları (Artificial Neural Networks – ANN)\nYapay sinir ağları, insan beynindeki sinir hücrelerinden (nöron) esinlenerek geliştirilmiştir.\nGirdi katmanı, bir veya birden fazla gizli katman ve çıktı katmanından oluşur.\nKatmanlar arasındaki bağlantı ağı sayesinde karmaşık örüntüleri öğrenme ve genelleme yeteneği yüksektir.\nDerin öğrenme modellerinin temelini oluşturur.\n\"\"\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bad29672-c7a2-4652-8a11-890b93a20442",
      "cell_type": "code",
      "source": "# 11.1 Linear kernel kullanılarak SVM modeli oluşturulması\nsvm_linear = SVC(kernel='linear', random_state=0)   # Doğrusal (linear) çekirdek ile SVM modeli tanımlanıyor\nsvm_linear.fit(x_train, y_train)                    # Model eğitim verisi ile eğitiliyor\ny_pred_linear = svm_linear.predict(x_test)          # Test verisi kullanılarak tahminleme yapılıyor\n\nac = accuracy_score(y_test, y_pred_linear)          # Tahminlerin doğruluk skoru hesaplanıyor\nprint(ac)                                           # Doğruluk oranı ekrana yazdırılıyor",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f87b4e74-fc6a-4c4c-9377-2dc858023439",
      "cell_type": "code",
      "source": "# 11.2 Polynomial kernel kullanılarak SVM modeli oluşturulması\nsvm_linear = SVC(kernel=\"poly\", random_state=0)     # Polinom çekirdek ile SVM modeli tanımlanıyor\nsvm_linear.fit(x_train, y_train)                    # Model eğitim verisi ile eğitiliyor\nsvm_pred = svm_linear.predict(x_test)               # Test verisi kullanılarak tahminleme yapılıyor",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "370517ba-7b2d-4292-bbee-630ca4afe446",
      "cell_type": "code",
      "source": "# 11.3 RBF (Radial Basis Function) kernel kullanılarak SVM modeli oluşturulması\nsvm_rbf = SVC(kernel=\"rbf\", random_state=0)      # RBF çekirdeği ile SVM modeli tanımlanıyor\nsvm_rbf.fit(x_train, y_train)                    # Model eğitim verisi ile eğitiliyor\nsvm_pred = svm_rbf.predict(x_test)               # Test verisi kullanılarak tahminleme yapılıyor",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6f471171-6979-47aa-bb2e-6401256c4f3e",
      "cell_type": "code",
      "source": "#12\n# RandomForestClassifier kullanılarak model oluşturulması ve değerlendirilmesi\nrf = RandomForestClassifier(random_state=0)             # Rastgele orman modeli tanımlanıyor\nrf.fit(x_train, y_train)                                # Model eğitim verisi ile eğitiliyor\ny_pred_rf = rf.predict(x_test)                          # Test verisi ile tahminleme yapılıyor\n\nprint(\"Random Forest Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))  # Karışıklık matrisi yazdırılıyor\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))    # Sınıflandırma metrik raporu (doğruluk, hassasiyet, F1 skoru vb.)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2000ec57-69e4-450d-85ed-2d4afab18660",
      "cell_type": "code",
      "source": "#13 \n# Decision Tree \ndt = DecisionTreeClassifier(random_state=0)  # Karar ağacı sınıflandırıcısı oluşturuluyor (rastgelelik kontrolü için random_state sabitleniyor)\ndt.fit(x_train, y_train)  # Model eğitim verisiyle eğitiliyor\ny_pred_dt = dt.predict(x_test)  # Test verisi üzerinde tahminleme yapılıyor\n\nprint(\"Decision Tree Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))  # Karışıklık matrisi yazdırılıyor\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))  # Sınıflandırma raporu (precision, recall, f1-score) yazdırılıyor\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f111af49-72a9-409c-b0aa-632aea00ea39",
      "cell_type": "code",
      "source": "#14\n# LogisticRegression\nlr = LogisticRegression(max_iter=1000, random_state=0)  # Logistic Regression modeli tanımlanıyor \nlr.fit(x_train, y_train)  # Model, eğitim verisiyle eğitiliyor\ny_pred_lr = lr.predict(x_test)  # Test verisi üzerinde tahminleme yapılıyor\n\nprint(\"Logistic Regression Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))  # Karışıklık matrisi yazdırılıyor\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))  # Sınıflandırma raporu (precision, recall, f1-score) yazdırılıyor\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "acfd5848-8747-4671-baed-a71daabb1c96",
      "cell_type": "code",
      "source": "#15\n# Yapay Sinir Ağları\nfrom sklearn.neural_network import MLPClassifier  # Çok katmanlı yapay sinir ağı (Multilayer Perceptron) sınıflandırıcısı import ediliyor\n\nann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=0)  # Tek gizli katmanlı (100 nöronlu) ANN modeli tanımlanıyor\nann.fit(x_train, y_train)  # Model, eğitim verileri ile eğitiliyor\ny_pred_ann = ann.predict(x_test)  # Test verisi üzerinde tahmin yapılıyor\n\nprint(\"ANN Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ann))  # Karışıklık matrisi yazdırılıyor\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_ann))  # Sınıflandırma raporu (precision, recall, f1-score) yazdırılıyor\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0e948f72-b8cf-47e4-9a08-71ed20537704",
      "cell_type": "code",
      "source": "# 16. Bölüm: Tüm sınıflandırma algoritmalarının doğruluk (accuracy) skorları karşılaştırılıyor\n\nprint(\"Yapay Sinir Ağları (MLP):\", accuracy_score(y_test, y_pred_ann))  # MLPClassifier (ANN) doğruluk skoru\nprint(\"Lojistik Regresyon:\", accuracy_score(y_test, y_pred_lr))  # Logistic Regression doğruluk skoru\nprint(\"Karar Ağacı:\", accuracy_score(y_test, y_pred_dt))  # Decision Tree doğruluk skoru\nprint(\"Rastgele Orman (Random Forest):\", accuracy_score(y_test, y_pred_rf))  # Random Forest doğruluk skoru\nprint(\"SVM (RBF kernel):\", accuracy_score(y_test, y_pred_rbf))  # SVM RBF çekirdeği doğruluk skoru\nprint(\"SVM (Polynomial kernel):\", accuracy_score(y_test, y_pred_poly))  # SVM polynomial çekirdeği doğruluk skoru\nprint(\"SVM (Linear kernel):\", accuracy_score(y_test, y_pred_linear))  # SVM linear çekirdeği doğruluk skoru\n\n# En iyi model, doğruluk skorlarına göre belirlenebilir",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d6158c72-c394-4d8a-ab3b-b887fe2a304e",
      "cell_type": "code",
      "source": "#Yorum satırlarını yapay zekadan yardım alarak yaptım hocam bilginiz olsun",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}